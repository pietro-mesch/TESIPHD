\chapter{A Real-Time Forecast-Based Genetic Algorithm}

The foremost aim of this work is to exploit the versatility and speed of advanced macroscopic traffic simulation to bring forth a heuristic approach capable of improving signal plans \emph{in real time}.
In this, it represents an attempt to bring together the best of most signal setting approaches described so far:
\begin{description}
\item[adaptive] aiming at real-time operation, it is hoped it might guarantee a degree of adaptivity so far only expected of \todo{adaptive online signal setting approaches described in ref?? using much simpler models}
\item[accurate] \todo{comprehensive model including real time data and less dependant on single sensors (see balmanual in case it says anything interesting about the stability of optima}
\item[heuristic] using heuristics avoid the simplifications required to formulate analytical approaches without compromising on accuracy in evaluating the outcomes
\item[gating] by evaluating forecast traffic conditions over a look-ahead window, it should behave more like a feedback controller, accounting at least for the short-term consequences of its decisions.
\todo{it should stay away from greedy solutions that may maximise the immediate efficiency of junctions while disregarding even the short-term effects which might include an increase in congestion}
\end{description}

This chapter presents the approach in detail, beginning with an introduction to the TRE macroscopic simulation engine, touching upon the most relevant features of the underlying model and framework, and finally describing the genetic algorithm implementation.

\todo{Optima! real networks! visum!}

\todo{anticipate sections better}


%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%

\section{TRE simulation engine and Optima framework}
The proposed optimisation method relies on the macrosimulation engine known as TRE, based on the eponymous Dynamic User Equilibrium assignment algorithm.
TRE lies at the core of the Optima traffic management software suite, developed in Rome by PTV SISTeMa\footnote{ITS spinoff of Sapienza University, now part of the Porsche group and partner in the present work \todo{???}} and running in traffic control centres around the globe, where it has time and again proven its reliability and forecast accuracy.\\
This section aims to illustrate its fundamental principles of operation, in order to clarify how they might affect the optimisation and better understand the role of the simulation engine within the architecture.

\subsection{Continuous Dynamic Traffic Assignment}
The general idea of \emph{Traffic Assignment} is rather intuitive: it is the modelling of the interaction between \emph{supply}, i.e. the roads, infrastructures and public transport options; and the \emph{demand} for mobility, i.e. people that need to travel using a choice of the available resources.

Since supply is limited, its availability and performance are a consequence of the choices made by users, which in turn are affected by the perceived discomfort of travelling across the network in the state it actually is: to predict with any plausibility the way in which traffic will spread across the network, it is necessary to resolve this reciprocal influence between supply and demand.

Of the many approaches proposed to this end throughout the history of transport research, the most successful are based on the \emph{Selfish User Equilibrium} principle first stated by \cite{wardrop1952}. This follows from the simple and sound behavioural assumption that every user will choose the route and mode of transport which are best for them, and implies that the most reasonably foreseeable traffic scenario is that in which no user would benefit from making a different choice: hence the notion of user \emph{equilibrium}.

Even in the simplest possible \emph{static} case, with steady demand and travel times only dependent on user choices, the equilibrium point must be found by an iterative process as illustrated in Figure \ref{f:dta}. Thus, at each iteration 
\begin{enumerate}
\item demand is routed through the network according to the arc costs, \\ and route flows are calculated;
\item the flows are assigned to the relevant arcs, \\ and costs are updated to account for congestion;
\item updated costs are checked against convergence criteria and, until these are met, \\ fed back into a new demand routing.
\end{enumerate} 

\fig{htbp}{PIX/undoguy.png}{f:dta}{\todo{General Dynamic Traffic Assignment} \citep{yperman2007link} p22}{width=0.4\textwidth}

In reality, demand is hardly constant throughout the day and congestion occurs as a consequence of the \emph{history} of the system; therefore any real-world application must account for the fact that travel times and user choices evolve \emph{dynamically} over time.

A \emph{Dynamic Traffic Assignment} (DTA) model allows to determine the dynamic interaction of supply and demand to predict the evolution of traffic conditions over any length of time, conceptually without further complication beyond the addition of the temporal dimension.

The user equilibrium condition can still be found via the mechanism illustrated in Figure \ref{f:dta}, working from the knowledge of demand and supply; with the difference that demand and user choices will be time dependent, and flows will propagate in space \emph{and time} so that arc costs become dynamic too. Traffic is considered to be a continuum, both as far as vehicle movements and trip-maker decisions are concerned.

Trip planning and route choice models are extremely relevant to the accuracy of a DTA and to the computational effort involved, but in the general DTA framework they are quite independent of each other and of the supply model.

The representation of traffic as it propagates and interacts with the network and signals, and all related phenomena within the scope of the present study, fall upon the Dynamic Network Loading model.
The most suitable macroscopic model for the task at hand is the General Link Transmission Model, which will be analysed in further detail over the next few sections.

\subsection{General Link Transmission Model}
The \emph{General Link Transmission Model}, henceforth referred to as GLTM, is a model for continuous dynamic network loading: it can be used to determine time-dependent link flows $\flow_{a,\tau}$ and travel times $\traveltime{a,\tau}$ given the time-dependent route flows.

It is built upon the representation of traffic as a partially compressible one-dimensional fluid flowing through the network according to the principles of \emph{Kinematic Wave Theory} (KWT), as developed independently by \cite{lighthill1955kinematic} and \cite{richards1956shock}.

Its origins can be traced back to the \emph{Cell Transmission Model} first presented in relation to highway traffic by \cite{daganzo1994cell} and shortly after applied to network traffic in \citep{daganzo1995cell}. CTM was the first dynamic traffic representation based on hydrodynamic theory, and borrowed heavily from that field, as is most evident from the cell-based space discretisation of the road network adopted directly from computational fluid dynamics.

The need for cell discretisation was eliminated in the \emph{Link Transmission Model} presented by \cite{yperman2005link}. This innovative approach allowed dynamic network loading of large scale networks using a computationally efficient algorithm that only required calculations at intersection nodes, while solving for traffic propagation along whole links using kinematic wave theory: this allowed to do away with a significant complexity factor while still accurately modelling local flow restrictions and junction delays.

The original LTM, presented in full detail in \cite{yperman2007link}, rather simplified the wave propagation problem relying on the \emph{simplified} kinematic wave theory proposed by \citep{newell1993simplified}, whereby only two possible wave propagation speeds are contemplated: a forwards one for free-flowing traffic, and one for the congested flow states to propagate backwards.
This is a considerable approximation, as the relation between vehicle density, speed and the resulting flow is rather more complex in reality:
the instrument provided by kinematic wave theory to express such relations in general is the Density-Flow Fundamental Diagram, illustrated in section \ref{s:fundiag}.

While in truth the work of Yperman already improved on the simplified KWT approach to include any piecewise linear fundamental diagram, the GLTM presented in \cite{gentile2010general} was developed to extend the LTM formulation to any concave fundamental diagram, considerably improving the accuracy in representing delays due to congestion. The GLTM also uses time-varying capacity adjustments at nodes to accurately model conflicts at intersections and the so called \emph{spillback} of traffic states from downstream links to the relevant upstream ones.

The features of the supply model described in the next sections, together with the computational efficiency and the possibility to perform a DTA in high temporal resolution, make the General Link Transmission Model an optimal candidate for the present application.


\subsection{Link Model}
In the GLTM, traffic propagates along links according to kinematic wave theory.
As stated in section \ref{s:urbannetwork}, links are assimilated to weighted arcs of a directed graph, and as such are one-dimensional, one-directional and homogeneous along their length, stretching between locations $x^0$ (the tail node) and $x^1 = x^0 + \length$ (the head node): the actual link shape is inconsequential. As far as the arc model is concerned, there is no need to disambiguate arcs since they exist and are processed independently: arc subscripts can be dropped for ease of reading but are to be implied on all relevant quantities henceforth.

The traffic state at a specific location $x \in \left[x^0, x^1\right]$ along a link is characterised by three macroscopic variables:
\begin{description}
\item[flow] $\flow_x$ : vehicles through the link section per unit time;
\item[density] $\density_x$ : average number of vehicles per unit length;
\item[speed] $\speed_x$ : average distance covered per unit time.
\end{description}
As is evident from their dimensions, only two of these quantities can be independent, and if two are known the third may be readily calculated using the relationship
\eq[.]{e:trafficstates}{\speed = \frac{\flow}{\density}}

The idea that vehicle density and speed can be completely independent, however mathematically sound, does not seem practically plausible. Kinematic wave theory provides a device for solving this contradiction as illustrated in the following section.

\subsubsection{Fundamental Diagram} \label{s:fundiag}
Kinematic wave theory assumes a functional relation between traffic density and flow, known as the \emph{Fundamental Diagram} of traffic flow. It approximates the changes in the average behaviour of drivers as the road gets more crowded, and may take several forms, but invariably follows from the properties of the road, e.g. width, slope or parking. As such it is itself, conceptually, a property of the link, although it could also be made to depend on environmental factors and driver behaviour, or be specific to a particular class of vehicles.

A generic fundamental diagram expresses the relationship between flow and density under \emph{stationary} traffic conditions, i.e. it is derived as an equilibrium condition between flow speed and available space taking the general form
\eq{e:fundiag_generic}{
q = f(k)
}
which may be represented on a Density-Flow graph like the ones shown in Figure \ref{f:fundiag}.
\fig{htbp}{PIX/undoguy.png}{f:fundiag}{Fundamental Diagram of a link, representing the functional relation between vehicular density and speed, resulting in different flow values for different congestion levels. Triangular form (left) and ??? form (right) are similarly shaped around the critical density value $\hat{\density}$, the jam density $\density_{jam}$ and the free flow speed $\vzero$.}{width=0.4\textwidth}

The shape of a fundamental diagram reflects different assumptions about traffic flow dynamics, but there are a few key features that are shared by all formulations:
\begin{itemize}
\item when density approaches \emph{zero} the speed approaches the maximum value attainable on the link, i.e. the \emph{free flow} speed $\vzero$, but the flow tends to zero;
\item maximum flow occurs at the \emph{critical density $\hat{\density}$} also referred to as the link \emph{capacity};
\item beyond capacity, further increase in vehicular density induces a speed penalty that causes the flow to decrease;
\item when vehicles reach the \emph{jam density} $\density_{jam}$ they are packed as closely as possible, and come to a standstill;
\item for any flow state on the $k-q$ curve, the speed is given by the slope of the line connecting it to the origin;
\item the rising branch diagram (i.e. to the left of $\hat{\density}$) represents free flowing 
states, the descending branch represents congested states.
\end{itemize}

In a simple triangular diagram like the one shown in Figure \ref{f:fundiag} (left) the speed is assumed constant at its maximum value for all subcritical states, while above capacity it decreases linearly with density. More subtle modelling may yield a diagram shape more similar to Figure \ref{f:fundiag} (right), where the speed is shown to decrease even in subcritical conditions as the road gets more crowded due to the natural variance in driving speed which, as more vehicles become involved, yields a higher chance of having a slow vehicle delaying all the others \emph{(subcritical spacing)}.

 In both cases it is assumed that as density increases, the available space becomes insufficient to maintain safe distances between vehicles, causing drivers to slow down \emph{(hypercritical spacing)}.
\todo{analysis of shapes given in ref tiddi}

If a model is to rely on the fundamental diagram to hold for non-stationary traffic as well, it must allow vehicles to change speed instantly with infinite acceleration, as is the case with GLTM and in general with first-order implementations of KWT. \\
Higher order traffic phenomena such as the emergence of stop-and-go waves along the link, or fundamental diagram hysteresis (due to traffic states evolving asimmetrically when leading up to congestion or recovering from it) are knowingly neglected.

\subsubsection{Traffic State Propagation}
To understand how traffic states propagate on links, consider the \emph{cumulative flow} $N(x,t)$, \\ i.e. the number of vehicles that have passed location $x$ along a link before time $t$.

Assuming that vehicle conservation is respected along the link, i.e. that no vehicle is created or destroyed between the tail and the head node, the trajectory of the $n^{\mathrm{th}}$ vehicle to enter the arc can be traced on a time-space diagram as the locus of points for which $N(x,t) = n$ as shown in Figure \ref{f:txtraj}.

\fig{htbp}{PIX/undoguy.png}{f:txtraj}{vehicle trajectories}{width=0.4\textwidth}

The cumulative function $N(x,t)$ is clearly discontinuous in both time and space, but it is possible to consider a smooth approximation that is differentiable in either direction without altering the essence of the phenomenon. Flow and density values at a given location and time can then be expressed as the partial derivatives
\eq[,]{e:dndt}{\flow(x,t) =\frac{\partial N(x,t)}{\partial t}}
\eq[,]{e:dndx}{\density(x,t) =\frac{-\partial N(x,t)}{\partial x}}
the latter requiring a sign change simply because density is defined positive but the cumulative decreases along the positive spatial direction.

\todo{derive wave propagation speed}

\todo{derive conservation}

\todo{fifo and Newell-Luke Minimum Principle}

\todo{shockwaves}


\subsubsection{Lane Modelling}

\subsection{Node Model}
\todo{illustrate node model}

\section{GLTM as Flow Simulation}
The network loading and flow propagation model is central to the optimisation process proposed in this work.
So far, its position in the Dynamic Traffic Assignment has been clarified, but it may be useful to recapitulate and formalise what its input and output are as a stand-alone \emph{flow simulator} component; before proceeding to Section \ref{s:geneticalgo} where its role in relation to the Genetic Algorithm will be clarified. These are summarised in Figure \ref{f:dnl} and presented in more detail in the following sections.

\fig{htbp}{PIX/undoguy.png}{f:dnl}{ Dynamic Network Loading Input and Output}{width=0.4\textwidth}

\subsection{Simulation Input}
The General Link Transmission Model operates on the basis of
\begin{description}
\item[splitting rates] resulting from the aggregation of the dynamic route flows, used by the node model to distribute the outflow of an arc to its forward star;
\item[origin flows] representing the vehicles \emph{injected} at specific network locations at every simulation interval, according to the demand data.
\end{description}

It is obviously important that the input data cover the entire span of the simulation, if realistic results are to be obtained.
However, the time resolution of the input data is irrelevant and the algorithm can operate with constant values as well as weighted averages where the time intervals do not correspond; in fact, it is robust even with respect to incomplete input, since it may split flows based on the relative capacity of downstream arcs, and if demand flows are unknown they will simply be assumed to be zero.


\subsection{Real Time Data Integration}
The GLTM implemented in TRE can draw real-time corrections from the OPTIMA framework, which are based on harmonised data coming from a variety of public and private sources (loops, cameras, floating car data etc.) which are integrated into the simulation as:
\begin{description}
\item[capacity corrections] when an accident, road closure or other modification to the supply is broadcast by the authorities or inferred automatically, and the fundamental diagram of the relevant arcs is updated;
\item[speed corrections] when the speed is measured or inferred, and either the fundamental diagram is updated to match the traffic state or a flow correction is applied;
\item[flow corrections] when a real flow value (often the outflow from an arc) is available and the simulated value overwritten.
\end{description}

These corrections are all applied in the inner loops of Figure \ref{f:dnl}, during the simulation intervals for which they are relevant. Their effect is then propagated in time and space, increasing the fidelity of the simulation to the real world traffic conditions.


\subsection{Simulation Output} \label{s:output}
\todo{Specify what quantities are ultimately calculated in a TRE simulation and can be considered its output.}


\subsection{Optimisation Corridor}
The present work aims to optimise signal timings in relation to the performance of what is usually called a \emph{Traffic Corridor} or \emph{Arterial Road}, referring to a stretch of road designed or happening to carry particularly high volumes of traffic. \\
While the concept is not strictly related to urban traffic, it is in the urban environment that traffic corridors most often suffer significant performance degradation due to congestion, aggravated by the numerous intersections with other busy roads where consistent traffic flows compete for the right of way and must be regulated by traffic lights.

The proposed optimisation method revolves around an \emph{Optimisation Corridor} object that essentially implements the formalisation illustrated in Section \ref{s:corridor}. It consists of an \emph{ordered set of links} connected head-to-tail, and may run through any number of signalised intersections: the problem size is then determined exactly, since the task at hand is simply to optimise signal coordination and each junction has a predetermined program that can only be offset in time.

This definition of corridor blends seamlessly into the Optima network model as well as in TRE result computation, and allows relevant key performance indicators to be calculated from continuous network loading results, i.e. the link \todo{???} just introduced in section \ref{s:output}: the process is fully detailed in Chapter \ref{c:objectives} where performance indicators are defined and discussed.

The corridor object represents the interface between the optimisation and simulation processes, and allows their separation (as may be more clear from Figure \ref{f:trega}), leaving the possibility to exploit the work done in this context e.g. with different optimisation methods. Although for the rest of this dissertation only one corridor will be considered, the application might easily be scaled to multiple corridors or extended to sub-networks: such efforts are beyond the scope of this experiment but their potential is discussed in \ref{s:scalability} alongside other scalability considerations.

Finally, it should be noted that links that are not strictly part of the corridor are \emph{not} factored into the KPI computation. Some may be considered relevant, e.g. the inroads to the corridor; however, it is far from straightforward to \emph{automatically} determine which links should be included based solely on the corridor definition, and in general there is no guarantee that the network model should be constructed in such a way as to render it possible at all. Although \emph{in principle} some consideration for the consequences of choices made on the corridor on the neighbouring roads may help make better decisions, this would require preprocessing of the network and the associated complications are deemed unnecessary given the current task, but will be discussed in Chapter \ref{c:futurework}.

\subsubsection*{Return Corridor Definition}
The return corridor cannot simply be defined as the sequence of links traversing the same nodes in reverse order: there is no guarantee that for any pair of subsequent nodes representing the tail and head of a given link there should exist another link joining them in the opposite direction.

Furthermore, the two directions of a traffic corridor may well be modelled as completely disjoint sets of arcs, sharing no nodes between them.

The present approach can handle two-way optimisation without loss of generality in this respect: it is sufficient to define the return corridor in the exact same way as the primary direction, and to indicate it as \emph{return} direction along with a weight coefficient.

If the junctions traversed by the return corridor are handled by the same set of controllers as the main, the problem size remains the same and the extra computation time required to calculate the relevant KPI is practically negligible. If more controllers are involved, they can be ignored (which makes little sense unless they actually cannot be controlled and adjusted remotely) or included in the optimisation, which will increase the solution space size and the time required to explore it.

%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%

\section{Genetic Algorithm} \label{s:geneticalgo}
\todo{Describe implementation, adaptations and tuning}

\subsubsection*{Time Dependent Weighting of Cost Functions}



\subsection{Initial Population Seeding with Slack Bandwidth}
\todo{Describe how the slackband is implemented to initialise the population and obtain better solutions faster.}


%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%

\section{Online Heuristic Optimisation}
\todo{Describe the task at hand and the interaction between TRE/GA.}\\
Condizioni dei test di TRE:
\begin{enumerate}
\item TRE fa un equilibrio e produce TPRB per tutto il giorno: gli intervalli sono ben più lunghi di un ciclo di semaforo quindi le svolte sono mediate e dipendono solo da domanda e green share
\item TRE salva l'istantanea dei flussi per cominciare le simulazioni di ottimizzazione a rete carica
\item Gli offset vengono modificati e per ogni individuo si fa un caricamento al secondo su una finestra temporale ristretta, partendo dall'istantanea salvata
\end{enumerate}

\fig{htbp}{PIX/undoguy.png}{f:trega}{ Interaction between the optimiser and TRE}{width=0.4\textwidth}

Funzionamento generale, pregi e limitazioni rispetto all'applicazione come ottimizzatore.




Quale intervallo di risultati si può usare? Data l'incertezza e le approssimazioni, ha senso usare i risultati al secondo?

Non varrebbe la pena guadagnare tempo usando intervalli di 6s ?
\emph{Non importa, si guadagna tempo ma per ora il tempo non ci preoccupa. Semmai si fa una prova a posteriori una volta determinato quale combinazione degli altri parametri funziona meglio}.





