\chapter{Smart Objectives} \label{c:objectives}
The very idea of optimisation cannot transcend the definition of its objectives: in fact, any search for an \emph{optimum} in any context first requires a clear answer to the question:
\begin{center}
what \emph{ is } good?
\end{center}

This chapter presents a few fundamental questions that must \emph{lead up} to the definition of the optimisation objectives, to point out what might have gone wrong in the past and illustrate how simulation-based optimisation might suit future developments in traffic optimisation.

Finally, the network performance indicators used in this study are presented and discussed in relation to the model outputs described in Chapter \ref{c:tools}.

\section{The Optimisation Dilemma}
When it comes to making choices about the development of the spaces we live in, and compromising between opposing interests, any responsible policy maker will be afflicted by the nagging doubt: \emph{will this actually be good for us in the long run?} Our recent history is full of sad examples of daft resource allocation driven only by someone's good will to improve our lot.
Dishonesty and deceit notwithstanding, the task of determining far-sighted policies truly in the best interest of the majority of people (let alone of the only habitable planet we know of) is a colossal one, and riddled with contradictions to boot.

Although the difficulty of \emph{identifying good} permeates almost every aspect of the human experience, it can be examined in this context with a most fitting example. The development of transport systems, hand in hand with the evolution of the very idea we hold of \emph{human mobility} (i.e. how far and fast we think we should be able to travel), has seen a vertiginous acceleration over the last century, propelled by technological progress and economic growth. It serves as a stark example of what, with the best yet sorely misguided intentions, we can end up doing to ourselves: ancient cities are eroded and clogged by grinding traffic, more modern ones \emph{sprawl} for miles in a highway-fed flight for space \todo{cite}.

The century of the car has taught us to make better, wider roads, to grant \emph{everyone} the right to faster and more efficient private transport, for the best of all... and left us with health and safety hazards beyond reason; inhospitable cities where \emph{human beings} have to contend their living space with (mostly stationary) cars, as public service is dismantled, distances grow and walking ceases to be an option. Most ironically, the very cars to whom we handed over our cities, have nowhere to go, and tax our waking time with dreadful walking-pace commuting and prowling for parking.

It is only natural then, when talking about signal optimisation, to be aware of not one but several \emph{elephants in the room}:
\begin{itemize}
\item signal optimisation is sound in principle, as it represents a way to maximise \emph{efficiency} of the already existing infrastructure, minimising the \emph{waste} of time: unfortunately, considering the fact that demand for private transport always closely matches the supply \todo{cite}, and that it is in direct competition (undercutting revenues and subtracting space) with its more sustainable alternatives \todo{cite}, any improvements to the supply tend to be quickly saturated, turning as a matter of fact into an overall \emph{loss};
\item not only to ease private traffic is of dubious benefit to our cities, health and safety; there isn't even a clear picture to understand whether the approaches followed thus far (e.g. bandwidth maximisation) are really beneficial to traffic fluidity in the short term, or if the worshipped \emph{green waves} lead to \emph{worse} traffic conditions in the more critical areas of urban networks.
\end{itemize}

It is true that it is extremely hard to model these effects explicitly, which is why this work aims to contribute to the affirmation of heuristic approaches that may help investigate the consequences of different choices, and maybe reverse-engineer better traffic control policies. It is also why, rather than tackling the rather more daunting challenge of \emph{re-defining good}, this proof-of-concept revolves around rather familiar performance indicators such as average progression speed and queue length.

It is of \emph{fundamental} importance, however, to understand that at least conceptually this approach does not make \emph{assumptions} about what the best design policies should be, but focusses on the \emph{results}.

Putting aside the cold hard fact that the only way to alleviate traffic is to \emph{reduce it} (as many cities around the world are finally doing, with \emph{well quantifiable} economic and psychological gains \todo{cite}, the plan is to try and see if at least we can be sure to actually \emph{reduce} the short term discomfort and externalities by increasing the efficiency of the existing roads with low-cost, non invasive infrastructure upgrades.

If the technology should prove effective, the object of its future developments might then well be to use simulation to enable \emph{long term} traffic control policies and define the objectives of optimisation in terms of modal shift to cycling and public transport, and in general tie them to the regaining of public spaces.

\section{Optimisation Objective Functions}

This section presents the objective functions used during this study to drive the Genetic Algorithm and obtain the results presented in Chapter \ref{c:results}.

They reflect very intuitive and down-to-earth objectives not dissimilar to the aims of classical optimisation techniques based on the analytical (and rather simplified) representations of congestion phenomena illustrated in Chapter \ref{c:basics}:
\begin{itemize}
\item \emph{minutes per kilometre travelled}, as a user-centred measure of discomfort;
\item \emph{stop ratio}, the minimisation of which is the presumed outcome of bandwidth maximisation;
\item \emph{relative queue length} as a measure of spillback and risk of gridlock.
\end{itemize}
These however are obtained directly from aggregation of the network performance model results (defined in section \ref{s:output}) thanks to existing and purpose-developed KPI calculation features of the simulation engine, as illustrated in the sections to follow.

\subsection{Fundamental Quantities}
The following quantities are calculated on the corridor over the entire simulation, and represent the reference quantities for calculation of key performance indicators.

The subscript $T$ is often dropped for readability, but is \emph{implied} for all quantities aggregated at the simulation span level and presented in the following section. 

\subsubsection*{Section and Corridor Total}
The \emph{section total} is defined as the integral of the inflow to a given section of the corridor $a \in \corridor$, obtained piecewise in this case, as the total number of vehicles entered during each interval of the simulation window:
\eq[.]{eq:stotal}{
\total{a} \; = \sum_{\tau \in \simspan} \flow_{a,\tau} \simintd
}

The \emph{corridor total} gives an aggregate measure of how frequented the corridor is on the whole: it does not carry information on which sections are busier, but accounts for all vehicles that accessed \emph{any} section during the simulation.

It is obtained as the cumulative total over all corridor sections, according to
\eq[.]{eq:ctotal}{
\total{\corridor} \; = \sum_{a \in \corridor} \total{a}
}

Notice that $\total{a}$ implies no distinction based on whether the flows are coming from the previous section of the corridor or from a cordon arc, therefore vehicles travelling on more than one section are counted several times. 
This reflects the fact that the corridor is being used \emph{more} if vehicles travel a greater portion of it than if they only were to use one section.

The total inflow index $\total{\corridor}$ covers an important role as a \emph{checksum}, since it ensures that any improvements in other cumulative indices are not really due to the corridor accepting fewer vehicles because of a deterioration in the traffic conditions.

\subsubsection*{User Time Spent and User Time Travelled}
The most direct way to calculate how much time is spent by users on the corridor during the simulation window is to integrate the total number of vehicles present on any section over all time intervals. The total and section \emph{User Time Spent} can be expressed as
\eq{eq:utspent}{
\utspent{\corridor} \; = \sum_{a \in \corridor} \utspent{a} \qquad \mathrm{where}
\qquad \utspent{a} = \sum_{\tau \in \simspan} \nveh{a,\tau} \simintd
}
therefore accounting for any vehicles already on the corridor at the start of the simulation, but not for the time that will be spent to get out of it beyond the end of the look-ahead window.
However, since it is impossible to know how much time the vehicles have \emph{already} spent on the corridor when the simulation begins, nor how far they have got down the arc they're found on, the time spent $\utspent{}$ is not suitable for estimating the corridor performance with respect to travelled distances. 

Disregarding the initial vehicles $\nveh{\corridor}$ and only considering flows that enter a corridor section during the simulation, it is possible to extrapolate from the results exactly how much time those vehicles will spend \emph{travelling} the length of each arc, even beyond the end of the simulation. The average \emph{User Time Travelled} is still a measure of time, but obtained from flows and travel times as
\eq[.]{eq:uttravelled}{
\uttravelled{a} = \sum_{\tau \in \simspan} \traveltime{a,\tau} \; \flow_{a,\tau} \; \simintd
}

\subsection{Performance Indicators}

\subsubsection{Minutes per Kilometre Travelled}
From the user point of view, it makes sense to evaluate the performance of the corridor by considering the time required to travel the desired distance.

Referring to the User Time Travelled $\uttravelled{a}$ expressed by \eqref{eq:uttravelled} the \emph{Minutes per Kilometre} cost function
\eq[]{eq:timedist}{
\timedist{\corridor} =
\sum_{a \in \arcset} 
\frac{\uttravelled{a}}{\; \length_a \quad \total{\corridor} \;} \cdot \frac{1000}{60}
}
uses the travel times experienced by all users, normalised with respect to the relevant section lengths and averaged over all vehicles involved with any part of the corridor during the simulation. This gives an overall measure of the fluidity of traffic on the corridor, and has the dimensions of a time per unit length. The choice of units (and name) for this performance indicator is therefore dictated solely by human-readability: it makes sense to count minutes spent in traffic to cover one kilometre, and it is easy to refer to the fact that for an average speed of 60 km/h the value of $\timedist{}$ would be 1.

\subsubsection{Stop Ratio}
The objective that most closely resembles the \emph{ideal} outcome of bandwidth maximisation is the stop ratio. While in section \ref{s:performance} this was modelled under the assumption of \emph{uniform arrivals} it is evident that for arterial progression optimisation it is necessary to consider the within-cycle dynamics of vehicle arrivals to account for the platooning effect of signals.

This is often done by propagating the cyclic flow profiles rigidly all the way to the next junction, and integrating them into the queue if they reach it when the signal is red, as illustrated in Figure \ref{f:scoot}. In this case the flow propagation performed by TRE is not only more realistic, but also accounts for the queue growth and spillback, which may cause a vehicle to stop well before the stop line.

\todo{formula a minchia con QUEU per cui vatte a vede larticolo}
Numero di fermate non è male, calcolato come integrale dell'aumento della QUEU in ogni intervallo, corretto aggiungendo l'eventuale deflusso se la coda alla fine dell'intervallo non si è azzerata.
Questo comporta degli errori (da quantificare esattamente?) negli intervalli in cui la coda comincia o finisce.
$$
\sum_{a \in C} \sum_{t \in T} QUEU_{a,t} - QUEU_{a,t-1} + OFLW_{a,t} \Delta t
$$

Il tutto è da normalizzare rispetto al numero di veicoli entrati su qualsiasi arco.


\subsubsection{Congestion}

Altro obiettivo utile sarebbe guardare la congestione degli archi.
Prendendo la congestione media si auto-pesano di più gli archi corti, il che avrebbe senso.
Come indicatore della congestione, dal GLTM prendiamo la lunghezza della coda peggiore nell'intervallo rispetto all'arco $QUEL\in[0,1]$ quindi come funzione di costo
\eq{e:maxqueue}{
Q_{a}^{MAX} = \sup\{QUEL_{a,t}|t\in T\}
}


\subsection{Dynamic Weighting}
In order to magnify the short-term effects of signal timings on the traffic conditions, and isolate them from the \emph{initial} situation in which they are enacted, it is possible to further shape the cost function by using time-dependent weights. This allows, for example, to give \emph{more relevance} to the traffic conditions towards the end of the interval, favouring solutions that bring about a \emph{negative} trend in the performance indicators (such as a progressive dissipation of the queues on a short arc) over solutions that lead to steady-state conditions, whence they may be indistinguishable if the results were simply time-averaged.

A generic scalar cost function $\omega$ of the decision variable $x$
\eq{e:dynw1}{\omega(x) = \int_{t \in \simspan} \omega(x,t)}
may be shaped using a generic function of time $\Theta(t)$ as in
\eq{e:dynw2}{\omega^{*}(x) = \int_{t \in \simspan} \Theta(t) \cdot \omega(x,t) }
which may take any form, e.g. it could be a step function to cut off a portion of the initial values, or a linear function of ${t}/{|\simspan|}$.

An analysis and comparison of the results obtained using each of the metrics just introduced is presented in the \nameref{c:results} chapter.